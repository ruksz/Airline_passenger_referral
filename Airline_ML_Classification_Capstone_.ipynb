{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "7wuGOrhz0itI",
        "578E2V7j08f6",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruksz/Airline_passenger_referral/blob/main/Airline_ML_Classification_Capstone_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Airline Passenger Referral Prediction\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Rukshar Shaikh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Airline Recommendations from Customer Reviews\n",
        "\n",
        "This project is focused on analyzing customer reviews of various airlines and building a predictive model to determine whether a customer will recommend an airline based on their review and overall experience. The dataset used for this analysis contains valuable information about customer sentiments, ratings, and preferences, which can provide significant insights into understanding customer satisfaction and improving airline services.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary objective of this project is to develop a robust machine learning model that can classify whether a customer will recommend an airline or not. This classification task is based on the sentiment expressed in the customer's review, the overall rating they provide, and other relevant features. By solving this problem, we aim to help airlines understand the factors influencing customer recommendations and enhance their services accordingly.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data = pd.read_excel('/content/drive/MyDrive/MLProject/data_airline_reviews.xlsx')"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "hikrlZBgi6Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have 17 columns and 131895 rows in our data."
      ],
      "metadata": {
        "id": "EZVU7aZJoPrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Duplicate Values\n"
      ],
      "metadata": {
        "id": "uDrPnanJpBdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#counting  number of duplicated values\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "ozJWXzi7pKdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping the null values\n",
        "data.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "Q9t0bgSPpXza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "57BaiHIQpfOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Null Values"
      ],
      "metadata": {
        "id": "9zraHh2ep9xd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the last 5 rows, we can conclude that our dataset contains null values. Let's check the number of null values present for each of the columns of this huge dataset."
      ],
      "metadata": {
        "id": "fPeZiT20qEe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the null value count for each column\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "ybBt51Rkpn9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Overall discription of data\n",
        "data.describe().T"
      ],
      "metadata": {
        "id": "LhrJxsn4qZjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains information related to airline passenger reviews, encompassing attributes such as airline names, overall ratings, reviewer details, review dates, and textual customer feedback. It further includes data on flight-specific details like aircraft type, traveler type, cabin class, flight routes, and flight dates. Additionally, passengers have rated various aspects of their experience, including seat comfort, cabin service, food and beverage quality, entertainment, ground service, and value for money. The dataset also includes an indication of whether passengers recommend the airline. However, it is worth noting that there are missing values in some columns, and the dataset offers opportunities for sentiment analysis, satisfaction prediction, and insights into factors affecting passenger experiences."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "airline: The name or identifier of the airline being reviewed.\n",
        "\n",
        "overall: An overall rating or score given by passengers, possibly for their overall experience.\n",
        "\n",
        "author: The author or reviewer of the feedback.\n",
        "\n",
        "review_date: The date when the review was posted.\n",
        "\n",
        "customer_review: The text content of the passenger's review or feedback.\n",
        "\n",
        "aircraft: The type or identifier of the aircraft used for the flight.\n",
        "\n",
        "traveller_type: The type of traveler (e.g., business, leisure) who left the review.\n",
        "\n",
        "cabin: The cabin class or type (e.g., economy, business) the passenger traveled in.\n",
        "\n",
        "route: The route or destination of the flight.\n",
        "\n",
        "date_flown: The date when the flight took place.\n",
        "\n",
        "seat_comfort, cabin_service, food_bev, entertainment, ground_service,\n",
        "value_for_money: Ratings or scores for various aspects of the flight experience, such as seat comfort, cabin service, food and beverage, entertainment, ground service, and value for money.\n",
        "\n",
        "recommended: An indication of whether the passenger would recommend the airline or flight"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the unique values of the recommended column(target variable)\n",
        "data.recommended.unique()"
      ],
      "metadata": {
        "id": "Yb-3I5R3uGkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# copy of the current dataset and assigning to app_data\n",
        "df=data.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Percentage wise missing values.\n",
        "def missing_values_per_check(df1):\n",
        "    percent_missing = data.isnull().sum() * 100 / len(data)\n",
        "    missing_values_df = pd.DataFrame({'column_name': data.columns,\n",
        "                                     'percent_missing': percent_missing})\n",
        "    return missing_values_df.sort_values('percent_missing',ascending=False)"
      ],
      "metadata": {
        "id": "ghJy0n9CxKOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 Cabin type and overall service ratings (out of 10)\n",
        "\n",
        "# Create a barplot\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='cabin', y='overall', hue='recommended', data=data, palette=['green', 'red'])\n",
        "\n",
        "# Add labels and a legend\n",
        "plt.xlabel('Cabin Type')\n",
        "plt.ylabel('Overall Service Rating')\n",
        "plt.legend(title='Recommended', loc='upper right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here. Which cabin type has overall service ratings?\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the trip is rated above 8 for overall section, the trip is most likely be recommended by the travellers.\n",
        "\n",
        "If it is below 3 , the unhappy travellers has not referred the airlines to their friends irrespective of their cabin type."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 Wthe top 10 airlines with most trips\n",
        "\n",
        "# Get the number of trips each airline make.\n",
        "trip_by_airlines = data['airline'].value_counts()\n",
        "trip_by_airlines"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the top 10 airlines with most trips\n",
        "plt.figure(figsize=(20,5))\n",
        "trip_by_airlines[:10].plot(kind='bar')\n",
        "plt.xlabel('Airline Type')\n",
        "plt.ylabel('Count',fontsize=12)\n",
        "plt.title('Top 10 Airline ')\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qn90NhNjz0eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which airline made highest trips?"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have observed that the top 10 airlines with most trips are-\n",
        "\n",
        "Spirit Airlines\n",
        "\n",
        "American Airlines\n",
        "\n",
        "United Airlines\n",
        "\n",
        "British Airways\n",
        "\n",
        "Emirates\n",
        "\n",
        "china southern airline\n",
        "\n",
        "frontier airlines\n",
        "\n",
        "ryanair\n",
        "\n",
        "delta air lines\n",
        "\n",
        "turkish airlines"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# Calculate the count of ratings for each traveller_type\n",
        "traveller_type_counts = data['traveller_type'].value_counts()\n",
        "\n",
        "# Find the traveller_type with the highest count\n",
        "most_rated_traveller_type = traveller_type_counts.idxmax()\n",
        "\n",
        "# Create a pie chart\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.pie(traveller_type_counts, labels=traveller_type_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title(f'Distribution of Ratings by Traveller Type\\nMost Rated: {most_rated_traveller_type}')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which Traveller_type has more ratings?"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solo Leisure travellers has more ratings"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=data, x='cabin', hue='recommended', palette=['red', 'purple'])\n",
        "plt.title('Count of Recommendations by Cabin Type')\n",
        "plt.xlabel('Cabin Type')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Recommended', labels=['No', 'Yes'])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Which type of Cabin has more recommendation?\n"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Economy class has highest recommendation with bad reviews.\n",
        "\n",
        "Business class has second most recommended cabin type with good reviews.\n",
        "\n",
        "premium economy has equal reviews.\n",
        "\n",
        "first class is least recommend cabin type with good reviews."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Calculate the average ratings for food_bev and entertainment for all classes\n",
        "average_ratings = data.groupby(['cabin'])[['food_bev', 'entertainment']].mean().reset_index()\n",
        "average_ratings\n",
        "\n",
        "# Create a bar plot\n",
        "plt.rcParams['figure.figsize']=(8,6)\n",
        "average_ratings.plot(x=\"cabin\", y=[\"food_bev\", \"entertainment\"], kind=\"bar\")\n",
        "\n",
        "# Add labels and legend\n",
        "plt.title('Average Ratings of Food & Beverage and Entertainment in All Classes')\n",
        "plt.xlabel('Cabin Class')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.legend(title='Category')\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " what is the average ratings of Food_bev and entertainment given by passengers in different classes?\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Economy Class the average ratings of Food_bev and entertainment given by passenger is lowest compared to other cabin classes."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6  Creating a violin plot for cabin type and cabin service ratings\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(data=data, x='cabin', y='cabin_service', hue='recommended', split=True)\n",
        "plt.title('Cabin Type and Cabin Service Ratings')\n",
        "plt.xlabel('Cabin Type')\n",
        "plt.ylabel('Cabin Service Ratings')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Recommended', loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which cabin type has more service ratings?"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First class travellers are least likely to recommend the airlines they travel.\n",
        "\n",
        "Recommendation is most probable when the cabin service is given full star rating ie 5 out of 5 here.\n",
        "\n",
        "In economy class if we got ratings between 4 to 5, that means airlines recommended."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 Calculate the mean \"value_for_money\" ratings for each airline\n",
        "mean_ratings = data.groupby('airline')['value_for_money'].mean().reset_index()\n",
        "\n",
        "# Sort the airlines by mean \"value_for_money\" ratings and select the top 10\n",
        "top_10_airlines = mean_ratings.sort_values(by='value_for_money', ascending=False).head(10)\n",
        "\n",
        "# Create a barplot to visualize the mean \"value_for_money\" ratings for the top 10 airlines\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=top_10_airlines, x='airline', y='value_for_money', palette='viridis')\n",
        "plt.xlabel('Airline')\n",
        "plt.ylabel('Mean Value for Money Ratings')\n",
        "plt.title('Top 10 Airlines with the Highest Mean Value for Money Ratings')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 airlines for highest value for money ratings?"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These top 10 airlines are providing passengers with a higher perceived value for the cost of their services.\n",
        "Airlines with lower mean ratings may consider reviewing their pricing strategies or customer service to enhance the perceived value for money and potentially improve customer satisfaction."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = data.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#frequency distribution using histgram\n",
        "data.hist(bins=50, figsize=(20,15),color = 'blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KrBIvMbc2ZHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of overall feature ratings fall within the range of 1 to 2. Among these ratings, a rating of 1 is the most common, followed by a rating of 2.\n",
        "\n",
        "When analyzing the \"Seat comfort\" feature, it becomes evident that a rating of 1 is the most frequently given, while a rating of 4 comes second in terms of frequency.\n",
        "\n",
        "Regarding the \"Cabin service\" feature, the highest-rated score is 5, and the second-highest rating is 1.\n",
        "\n",
        "The \"Food and Beverage\" feature ratings of 2, 4, and 5 are distributed fairly equally, indicating that their frequencies are approximately the same.\n",
        "\n",
        "Both the \"Entertainment\" and \"Ground service\" features show that a rating of 3 is the most commonly assigned, while a rating of 1 is the second most frequent.\n",
        "\n",
        "The \"Value for money\" feature reveals that a substantial number of passengers assign a rating of 1, implying that many airlines may not be delivering satisfactory service to passengers."
      ],
      "metadata": {
        "id": "vk8-raLz26vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "EAnX79lEoU29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Droping Unnecessary columns**\n"
      ],
      "metadata": {
        "id": "J9xER4RUPG_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Percentage wise missing values.\n",
        "def missing_values_per_check(df1):\n",
        "    percent_missing = data.isnull().sum() * 100 / len(data)\n",
        "    missing_values_df = pd.DataFrame({'column_name': data.columns,\n",
        "                                     'percent_missing': percent_missing})\n",
        "    return missing_values_df.sort_values('percent_missing',ascending=False)\n",
        ""
      ],
      "metadata": {
        "id": "keavEVXaPsYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " this function is a convenient way to analyze and report the extent of missing data in each column of a DataFrame. It can help you identify which columns have the most missing values, which is valuable for data preprocessing and cleaning tasks."
      ],
      "metadata": {
        "id": "ral8IaAhr3MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Percentage wise missing values.\n",
        "missing_values_per_check(data)"
      ],
      "metadata": {
        "id": "jDBkuD3mP_cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the number of unique aircrafts\n",
        "data.aircraft.nunique()"
      ],
      "metadata": {
        "id": "Iq4i0_DTQNN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['aircraft'],axis = 1)"
      ],
      "metadata": {
        "id": "wUO5DeXjQVtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping the columns from data which are not for our use\n",
        "data = data.drop(['author','review_date','route','date_flown','customer_review'],axis = 1)"
      ],
      "metadata": {
        "id": "Y76yvnjPQdYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(axis=1, how='all')"
      ],
      "metadata": {
        "id": "iblgYuPXgnjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "G9CfbPJFdjkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the Numeric column\n",
        "low_null = ['overall','seat_comfort','cabin_service','value_for_money']\n",
        "high_null = ['food_bev','entertainment','ground_service']"
      ],
      "metadata": {
        "id": "NqNau7U7oViS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation technique using Quantile-1 value\n",
        "def impute_by_q1_values(data,column):\n",
        "  Q1=np.percentile(np.sort(data[column].dropna()),25)\n",
        "  data[column].fillna(Q1,inplace=True)"
      ],
      "metadata": {
        "id": "VpHsnDLMoeCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looping the null value column\n",
        "for col in low_null:\n",
        "  impute_by_q1_values(data,col)"
      ],
      "metadata": {
        "id": "uMzQNBljovqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation technique using Median Imputation\n",
        "def median_imputation(data,column):\n",
        "  data[column].fillna(data[column].median(),inplace=True)"
      ],
      "metadata": {
        "id": "FaCAEK75ox78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looping the null value column\n",
        "for col in high_null:\n",
        "  median_imputation(data,col)"
      ],
      "metadata": {
        "id": "RY7InSrrpp0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after imputed null values\n",
        "data.head(1)"
      ],
      "metadata": {
        "id": "oXlGiisKp8V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove recommended null value row\n",
        "data.dropna(subset=['recommended'],inplace=True)"
      ],
      "metadata": {
        "id": "qA-vpMhVqR0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['traveller_type'].fillna(method=\"ffill\",inplace=True)"
      ],
      "metadata": {
        "id": "fdMs4WB1qfLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cabin'].fillna(data['cabin'].mode().values[0],inplace=True)"
      ],
      "metadata": {
        "id": "QlmPz1h0q0vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(1)"
      ],
      "metadata": {
        "id": "R7canCQ8q78y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the new null value percentage\n",
        "missing_values_per_check(data)"
      ],
      "metadata": {
        "id": "nMcpP_SerCRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "tV83efjTrI7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "Passengers who rate \"seat_comfort\" higher are more likely to recommend the airline."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the mean \"seat_comfort\" ratings between passengers who recommend and those who do not recommend the airline.\n",
        "\n",
        "Alternative Hypothesis (H1): Passengers who recommend the airline have a significantly higher mean \"seat_comfort\" rating compared to those who do not recommend it."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Remove missing values from seat_comfort_recommend and seat_comfort_not_recommend\n",
        "seat_comfort_recommend = data[data['recommended'] == 'yes']['seat_comfort'].dropna()\n",
        "seat_comfort_not_recommend = data[data['recommended'] == 'no']['seat_comfort'].dropna()\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = stats.ttest_ind(seat_comfort_recommend, seat_comfort_not_recommend, equal_var=False)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Check if the p-value is less than alpha\n",
        "if not p_value:\n",
        "    print(\"Invalid p-value (nan)\")\n",
        "elif p_value < alpha:\n",
        "    print(\"Reject the null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis\")\n",
        "\n",
        "# Print the p-value\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will calculate the t-statistic and p-value for the two groups based on their \"seat_comfort\" ratings and then determine whether to reject the null hypothesis or not. If the p-value is less than 0.05, we would reject the null hypothesis, suggesting that there is a significant difference in the mean \"seat_comfort\" ratings between the two groups."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "The average \"value_for_money\" rating for passengers who flew in Business Class is significantly higher than those who flew in Economy Class."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the mean \"value_for_money\" ratings between passengers who flew in Business Class and those who flew in Economy Class.\n",
        "\n",
        "Alternative Hypothesis (H1): Passengers who flew in Business Class have a significantly higher mean \"value_for_money\" rating compared to those who flew in Economy Class.\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Separate data for passengers who flew in Business Class and Economy Class\n",
        "value_for_money_business = data[data['cabin'] == 'Business']['value_for_money']\n",
        "value_for_money_economy = data[data['cabin'] == 'Economy Class']['value_for_money']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = stats.ttest_ind(value_for_money_business, value_for_money_economy, equal_var=False)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Check if the p-value is less than alpha\n",
        "if not p_value:\n",
        "    print(\"Invalid p-value (nan)\")\n",
        "elif p_value < alpha:\n",
        "    print(\"Reject the null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis\")\n",
        "\n",
        "# Print the p-value\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "Passengers who provide positive \"cabin_service\" ratings are more likely to recommend the airline."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the mean \"cabin_service\" ratings between passengers who recommend and those who do not recommend the airline.\n",
        "\n",
        "Alternative Hypothesis (H1): Passengers who recommend the airline have a significantly higher mean \"cabin_service\" rating compared to those who do not recommend it."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate data for passengers who recommend and those who do not recommend\n",
        "seat_comfort_recommend = data[data['recommended'] == 'yes']['seat_comfort']\n",
        "seat_comfort_not_recommend = data[data['recommended'] == 'no']['seat_comfort']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = stats.ttest_ind(seat_comfort_recommend, seat_comfort_not_recommend, equal_var=False)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results\n",
        "print(\"Hypothesis Test Results:\")\n",
        "print(f\"Null Hypothesis (H0): There is no significant difference in the mean 'seat_comfort' ratings between passengers who recommend and those who do not recommend the airline.\")\n",
        "print(f\"Alternative Hypothesis (H1): Passengers who recommend the airline have a significantly higher mean 'seat_comfort' rating compared to those who do not recommend it.\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Check if the p-value is less than alpha\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis\")\n",
        "    print(\"Passengers who recommend the airline have a significantly higher mean 'seat_comfort' rating.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis\")\n",
        "    print(\"There is no significant difference in the mean 'seat_comfort' ratings between the two groups.\")\n"
      ],
      "metadata": {
        "id": "NINxpby3wRd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose the t-test for the hypothesis testing in this case because it is appropriate when we want to compare the means of two independent groups. In this hypothesis, we are comparing the mean \"seat_comfort\" ratings of two groups:\n",
        "\n",
        "Passengers who recommend the airline.\n",
        "Passengers who do not recommend the airline.\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "\n",
        "#Done Above"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting target as categorical data into numerical data: 'Label Encoding'\n"
      ],
      "metadata": {
        "id": "sY3H6asGxPIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting targeted column\n",
        "data['recommended'].replace({'yes':1,'no':0},inplace=True)\n",
        "data.head(2)"
      ],
      "metadata": {
        "id": "SgJoxKRKxKVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Above correlation heatmap didn't include recommeded col which is target var hence did it here again\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(data.corr(), annot=True)"
      ],
      "metadata": {
        "id": "n9w4jWCvxaAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop overall column as it has highest correlation value than others."
      ],
      "metadata": {
        "id": "QR29wPtB7N-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to remove multicollinear\n",
        "def calc_vif(X):\n",
        "\n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "bAAzrziq7FN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(data[[i for i in data.describe().columns if i not in ['recommended','value_for_money','overall']]])"
      ],
      "metadata": {
        "id": "psj3YKoi7cJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop overall column\n",
        "data.drop([\"overall\"], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "KDK2SH659CYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop([\"airline\"], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "H-7jGEGY9HHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separating the dependent and independent variables\n",
        "y = data['recommended']\n",
        "x = data.drop(columns = 'recommended')"
      ],
      "metadata": {
        "id": "0kkq_b-P_ecF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.columns"
      ],
      "metadata": {
        "id": "yl37iLge_jzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One hot Encoding"
      ],
      "metadata": {
        "id": "KSExLMLc_RU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.get_dummies(x)"
      ],
      "metadata": {
        "id": "WwdRrYar_P0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head(2)"
      ],
      "metadata": {
        "id": "hClYHtEw_qo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "Gc1qPhxK_ukg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Percentage of No labels of Target Variable is\",np.round(y.value_counts()[0]/len(y)*100))\n",
        "print(\"The Percentage of Yes labels of Target Variable is\",np.round(y.value_counts()[1]/len(y)*100))"
      ],
      "metadata": {
        "id": "IWE0Pe_1_zvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Percentage of both labels('yes','no) is approximately equal. So no need of Handling Class Imbalance technique."
      ],
      "metadata": {
        "id": "UtOJj0QzANmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( x,y , test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of x_train and x_test data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "Ibfz1_0eAe5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of y_train and y_test data\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "g1tvW2zZAlg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the Algorithm\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = clf.predict(x_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Accuracy of Decision Tree Model is\",clf.score(x_train,y_train))\n",
        "print(\"Testing Accuracy of Decision Tree Model is\",clf.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "A7IOVTFSDtUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#report of decision tree\n",
        "report_dec_tree = classification_report(y_test, y_pred)\n",
        "print(report_dec_tree)"
      ],
      "metadata": {
        "id": "gXzFWvMrD5BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "Explained later"
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "#  Get the best hyperparameters from the grid search\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_clf = DecisionTreeClassifier(random_state=42, **best_params)\n",
        "best_clf.fit(x_train, y_train)\n",
        "\n",
        "#  Make predictions on the test set with the best model\n",
        "y_pred = best_clf.predict(x_test)\n",
        "\n",
        "#predicted values\n",
        "print(\"Predicted values:\", y_pred)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling an best score\n",
        "grid_search.best_score_"
      ],
      "metadata": {
        "id": "EVOonWiHIA69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used the GridSearchCV hyperparameter optimization technique.\n",
        " GridSearchCV is simple and straightforward, widely used, and exhaustively searches through all possible combinations of hyperparameters specified in the parameter grid."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "93% accuracy of Decision Tree with the help of hypermatring tunning."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "o3yVG6AcJF2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "3A_LV0WZJNOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "92% accuracy with Random Forest"
      ],
      "metadata": {
        "id": "g2yVmZNYfB2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#report of decision tree\n",
        "report_ran_forest = classification_report(y_test, y_pred)\n",
        "print(report_ran_forest)"
      ],
      "metadata": {
        "id": "Zo-Zvp4gJUXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for hyperparameter tuning\n",
        "parameters = {\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":[5,7],\"min_samples_split\":[5,7],\"min_samples_leaf\":[2,3]}\n",
        "\n",
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "random_forest_gridcv = GridSearchCV(estimator=random_forest,\n",
        "                       param_grid = parameters,\n",
        "                       cv = 5, verbose=2)\n",
        "\n",
        "# Fit the Algorithm\n",
        "random_forest_gridcv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters from the grid search\n",
        "best_params = random_forest_gridcv.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "id": "8XFnSHrzWqmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_gridcv.best_score_"
      ],
      "metadata": {
        "id": "1bKdC2ODXjfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "93% accuracy of Decision Tree with the help of hypermatring tunning."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "log_reg = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "log_reg.fit(x_train, y_train)\n",
        "\n",
        "print(log_reg.coef_)\n",
        "print(log_reg.intercept_)\n",
        "# Predict on the model\n",
        "y_pred = log_reg.predict(x_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#report of logistic regression\n",
        "report_lR = classification_report(y_test, y_pred)\n",
        "print(report_lR)"
      ],
      "metadata": {
        "id": "LX71UuZscc4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(log_reg.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "TMa6MklkdMFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "93% accuracy with Logistic Regression"
      ],
      "metadata": {
        "id": "uA9UIUpdYte7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cofusion matrix of logistic regression\n",
        "confuse_matrix_lr = confusion_matrix( y_test,y_pred)\n",
        "print(confuse_matrix_lr)\n",
        "#ploting confusion matrix\n",
        "sns.heatmap(confuse_matrix_lr, annot=True, fmt = \".1f\", cmap=\"viridis\")"
      ],
      "metadata": {
        "id": "buevFiZ06bBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Cross-validated Logistic Regression"
      ],
      "metadata": {
        "id": "3N0SQa0Q7U7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic = LogisticRegression()"
      ],
      "metadata": {
        "id": "ngU38q7-6sN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(log_reg, x_train, y_train, cv=10)\n",
        "print('Cross-Validation Accuracy Scores', scores)"
      ],
      "metadata": {
        "id": "7Fx7aJZZ7ee_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pd.Series(scores)\n",
        "scores.min(), scores.mean(), scores.max()"
      ],
      "metadata": {
        "id": "jdTSz22o7lSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(log_reg, x_train, y_train, cv=10)\n",
        "print('Cross-Validation Accuracy Scores', scores)"
      ],
      "metadata": {
        "id": "_-1jTz5m49q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum accuracy score achieved during cross-validation is 94.42"
      ],
      "metadata": {
        "id": "H6fxP2eI-QBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the evaluation metrics I used includes accuracy, precision, recall, and F1-score. These metrics provide a comprehensive view of the model's performance, considering both the positive and negative classes, and are common metrics for classification problems."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models=[clf,random_forest,log_reg]\n",
        "name=['Decision Tree Model After Hyperparameter Tuning','Random Forest Model After Hyperparameter Tuning','Logistic Regression']"
      ],
      "metadata": {
        "id": "dSKBzmI14kXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_of_each_model(model, x_train, x_test, y_train, y_test):\n",
        "    # Predicting train and test data\n",
        "    y_train_preds = model.predict(x_train)\n",
        "    y_test_preds = model.predict(x_test)\n",
        "\n",
        "    # Lists to store scores for each metric\n",
        "    train_scores = []\n",
        "    test_scores = []\n",
        "    metrics = ['Accuracy_Score', 'Precision_Score', 'Recall_Score']\n",
        "\n",
        "    # Get the accuracy scores\n",
        "    train_accuracy_score = accuracy_score(y_train, y_train_preds)\n",
        "    test_accuracy_score = accuracy_score(y_test, y_test_preds)\n",
        "\n",
        "    train_scores.append(train_accuracy_score)\n",
        "    test_scores.append(test_accuracy_score)\n",
        "\n",
        "    # Get the precision scores\n",
        "    train_precision_score = precision_score(y_train, y_train_preds)\n",
        "    test_precision_score = precision_score(y_test, y_test_preds)\n",
        "\n",
        "    train_scores.append(train_precision_score)\n",
        "    test_scores.append(test_precision_score)\n",
        "\n",
        "    # Get the recall scores\n",
        "    train_recall_score = recall_score(y_train, y_train_preds)\n",
        "    test_recall_score = recall_score(y_test, y_test_preds)\n",
        "\n",
        "    train_scores.append(train_recall_score)\n",
        "    test_scores.append(test_recall_score)\n",
        "\n",
        "    return train_scores, test_scores, metrics\n",
        "\n",
        "for model_idx, model in enumerate(models):\n",
        "    train_score_, test_score_, metrics_ = accuracy_of_each_model(model, x_train, x_test, y_train, y_test)\n",
        "\n",
        "    print(\"-*-*-\"*3 + f\"{name[model_idx]}\" + \"-*-*-\"*4)\n",
        "    print(\"\")\n",
        "    print(pd.DataFrame(data={'Metrics': metrics_, 'Train_Score': train_score_, 'Test_Score': test_score_}))\n",
        "    print(\"\")\n"
      ],
      "metadata": {
        "id": "kUaoE0pBdClw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the *Logistic Regression model* has achieved a competitive test accuracy and can be a reasonable choice, especially if interpretability is important. However, if maximizing accuracy is the primary goal and interpretability is less critical, the Random Forest model may be preferred."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Random Forest*\n",
        "It is an ensemble learning technique that combines multiple decision trees to make predictions. One of the benefits of Random Forest is its ability to assess feature importance, which helps understand the contribution of each feature to the model's predictions."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the three models that were used for classification problemare:\n",
        "\n",
        "\n",
        "\n",
        "1.  Decision Tree\n",
        "2.  Random Forest, and\n",
        "3.  Logistic Regression\n",
        "\n",
        "\n",
        "For Decision Tree:\n",
        "\n",
        "Hyperparameter tuning was performed to fine-tune the model. The priority for classification metrics was Recall, followed by Accuracy and ROC AUC.\n",
        "The Decision Tree model achieved competitive results in terms of accuracy.\n",
        "Interpretability is a notable advantage of this model.\n",
        "Key features for prediction included overall rating and Value for money.\n",
        "\n",
        "\n",
        "\n",
        "For Random Forest:\n",
        "\n",
        "We applied hyperparameter tuning to optimize the model's performance.\n",
        "The priority for classification metrics remained the same.\n",
        "Random Forest exhibited robust performance and accuracy above 90%.\n",
        "It combines multiple decision trees to handle complex relationships in the data.\n",
        "Important features for predictions were the overall rating and Value for money.\n",
        "\n",
        "\n",
        "For Logistic Regression:\n",
        "\n",
        "Like the other models, hyperparameter tuning was conducted.\n",
        "Similar priority for classification metrics was applied.\n",
        "Logistic Regression achieved an accuracy of over 90% and was chosen as the best-performing model.\n",
        "The most important features for prediction were the overall rating and Value for money.\n",
        "This model can help airlines identify influential passengers for revenue growth.\n",
        "\n",
        "\n",
        "In conclusion, all three models achieved high accuracy, and the choice among them depends on factors like interpretability and specific business goals. Logistic Regression stood out as the best model overall, but Decision Tree and Random Forest also provided valuable insights and competitive performance. Airlines can use these models to identify influential passengers and improve their services accordingly.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}